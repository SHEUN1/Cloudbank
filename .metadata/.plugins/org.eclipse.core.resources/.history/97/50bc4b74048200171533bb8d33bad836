//============================================================================
// Name        : transistor_vision.cpp
// Author      : 
// Version     :
// Copyright   : Your copyright notice
// Description : Extract objects and their features from a playing game
//============================================================================
#include<stdio.h>
#include<iostream>
#include<opencv2/core/core.hpp>
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include<opencv2/opencv.hpp>
#include<iostream>
#include<vector>
#include <algorithm>
#include <map>
#include <iterator>

#include "yingyang.h"
#include "SeperateObjects.h"
#include "featureextraction.h"
#include "SendDataToPython.h"


using namespace std;
using namespace cv;

#include <boost/python.hpp>
#include <boost/python/suite/indexing/vector_indexing_suite.hpp>
#include <boost/python/suite/indexing/map_indexing_suite.hpp>

using namespace boost::python;
typedef vector<double> MyList;

boost::python::dict vision_analysis()
{
		//this map will hold all the information on the image such as its position in the frame and feature points
		typedef int object; //object number
		typedef std::pair<int, int > coordinates; //this will hold x,y coordinates of object in the frame
		typedef vector<KeyPoint> featurePoints; // feature points of object


		std::map <object, std::pair<coordinates, featurePoints > > dark_object_info;
		std::map <object, std::pair<coordinates, featurePoints > > light_object_info;
		//hold coordinates to be later inserted for dark contrast objects
		vector<int>dark_x_coordinate;
		vector<int>dark_y_coordinate;
		//hold coordinates to be later inserted for light contrast objects
		vector<int>light_x_coordinate;
		vector<int>light_y_coordinate;

		// turn on script that save get current frame from video game
	    //system("/home/sheun/Gaming_Project/game_vision/gstream_command_to_capture_image &");

	    //read current video_game frame
	    Mat img = imread("/home/sheun/Gaming_Project/game_vision/current_game_frame.jpg");

	    //grayscale, and use imadjust for to get a high contrast version (the basIS for "lightworld")
		Mat gray;
		//convert to grayscale
		cvtColor(img, gray, COLOR_RGB2GRAY);

		//smooth image
		blur(gray, gray, Size(3,3));

		Mat Original_image_clone = gray.clone();

		//convert to binary
		ying_yang world_view;
		Mat dark_world_view = world_view.binary(gray,img);
		Mat light_world_view = world_view.binary_Inverse(gray,img);

		//get objects in each world view (light and dark contrast images) and put each of them into a vector
		SeperateObjects worldObjects;
		vector <Mat> dark_world_objects  = worldObjects.BoundBox(dark_world_view, gray,Original_image_clone, 0, dark_x_coordinate, dark_y_coordinate, false); // the 3rd parameter holds the version of the frame image that the boxes will be drawn onto the boxes to be on the original image
		vector <Mat> light_world_objects = worldObjects.BoundBox(light_world_view, gray,Original_image_clone, 1, light_x_coordinate, light_y_coordinate, false);

		feature_extraction features_of_objects;
		vector< vector<KeyPoint> > features_of_dark_world_objects = features_of_objects.featurePoints(dark_world_objects,0, false);
		vector< vector<KeyPoint> > features_of_light_world_objects = features_of_objects.featurePoints(light_world_objects,1, false);

		//Append vectors so that all objects can be put into the python dictionary
		features_of_dark_world_objects.insert(features_of_dark_world_objects.end(), features_of_light_world_objects.begin(), features_of_light_world_objects.end());


		//send data of objects in image to python
		SendDataToPython python_features_of_objects;
		boost::python::dict send_to_python_the_dark_world = python_features_of_objects.objectInformationToDict(features_of_dark_world_objects, dark_x_coordinate, dark_y_coordinate);

		return send_to_python_the_dark_world;

}

int main()
{

	vision_analysis();
	return 0;

}

BOOST_PYTHON_MODULE(main)
{

	 def("vision", vision_analysis);

}
