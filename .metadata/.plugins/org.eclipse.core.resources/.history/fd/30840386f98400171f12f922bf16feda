//============================================================================
// Name        : transistor_vision.cpp
// Author      : 
// Version     :
// Copyright   : Your copyright notice
// Description : Extract objects and their features from a playing game
//============================================================================
#include<stdio.h>
#include<iostream>
#include<opencv2/core/core.hpp>
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include<opencv2/opencv.hpp>
#include "opencv2/text/ocr.hpp"
#include<iostream>
#include<vector>
#include <algorithm>
#include <map>
#include <iterator>
#include <tesseract/baseapi.h>
#include <leptonica/allheaders.h>

#include "yingyang.h"
#include "SeperateObjects.h"
#include "featureextraction.h"
#include "SendDataToPython.h"
#include "OCR.h"

using namespace std;
using namespace cv;

#include <boost/python.hpp>
#include <boost/python/suite/indexing/vector_indexing_suite.hpp>
#include <boost/python/suite/indexing/map_indexing_suite.hpp>

using namespace boost::python;

int frameNumber = 0;
int activateImageCapture = 0;
boost::python::dict vision_analysis()
{

		//this map will hold all the information on the image such as its position in the frame and feature points
		typedef int object; //object number
		typedef std::pair<int, int > coordinates; //this will hold x,y coordinates of object in the frame
		typedef vector<KeyPoint> featurePoints; // feature points of object


		std::map <object, std::pair<coordinates, featurePoints > > dark_object_info;
		std::map <object, std::pair<coordinates, featurePoints > > light_object_info;
		//hold coordinates to be later inserted for dark contrast objects
		vector<int>dark_x_coordinate;
		vector<int>dark_y_coordinate;
		//hold coordinates to be later inserted for light contrast objects
		vector<int>light_x_coordinate;
		vector<int>light_y_coordinate;

		// turn on script that save get current frame from video game
		if (activateImageCapture == 0)
		{
			system("/home/sheun/Gaming_Project/game_vision/gstream_command_to_capture_image &");
			++activateImageCapture;

		}

	    //read current video_game frame
	    Mat img = imread("/home/sheun/Gaming_Project/game_vision/current_game_frame.jpg");
	//	Mat img = imread("/home/sheun/Pictures/transistor_images/transistor1.jpg");

	    //convert to grayscale
		Mat gray;
		cvtColor(img, gray, COLOR_RGB2GRAY);

		//smooth image
		blur(gray, gray, Size(3,3));

		//this is he image on which the bounded boxes will be drawn on
		Mat Original_image_clone = img.clone();

		//convert to binary
		ying_yang world_view;
		Mat dark_world_view = world_view.binary(gray,img);
		Mat light_world_view = world_view.binary_Inverse(gray,img);

		//get objects in each world view (light and dark contrast images) and put each of them into a vector
		SeperateObjects worldObjects;
		vector <Mat> dark_world_objects  = worldObjects.BoundBox(dark_world_view, gray,Original_image_clone, 0, dark_x_coordinate, dark_y_coordinate, false);
		vector <Mat> light_world_objects = worldObjects.BoundBox(light_world_view, gray,Original_image_clone, 1, light_x_coordinate, light_y_coordinate, false);

		//get feature points of each object
		feature_extraction features_of_objects;
		vector< vector<KeyPoint> > features_of_dark_world_objects = features_of_objects.featurePoints(dark_world_objects,0, false);
		vector< vector<KeyPoint> > features_of_light_world_objects = features_of_objects.featurePoints(light_world_objects,1, false);

		//Append/combine feature vectors so that all objects can be put into the python dictionary
		features_of_dark_world_objects.insert(features_of_dark_world_objects.end(), features_of_light_world_objects.begin(), features_of_light_world_objects.end());

		dark_x_coordinate.insert(dark_x_coordinate.end(), light_x_coordinate.begin(), light_x_coordinate.end());
		dark_y_coordinate.insert(dark_y_coordinate.end(), light_y_coordinate.begin(), light_y_coordinate.end());


		//get words in frame
		OCR word_capture;
		pair< vector<string>, vector < pair< int , int  > > > chracterInfo = word_capture.getWords(img);

		char file [100];

		sprintf(file,"/home/sheun/cloudbank_images/Bounded_box_on_image/Image%d.jpg",frameNumber);
		imwrite(file,Original_image_clone);

		sprintf(file,"/home/sheun/cloudbank_images/objects_waterfall_binary/darkworld/Image%d.jpg",frameNumber);
		imwrite(file,dark_world_view);

		sprintf(file,"/home/sheun/cloudbank_images/objects_waterfall_binary/lightworld/Image%d.jpg",frameNumber);
		imwrite(file,light_world_view);
		++frameNumber;
		if (frameNumber==500){frameNumber=0;}


		//send data of objects in image to python
		SendDataToPython python_features_of_objects;
		boost::python::dict send_to_python_the_dark_world = python_features_of_objects.objectInformationToDict(features_of_dark_world_objects, dark_x_coordinate, dark_y_coordinate, chracterInfo);

		return send_to_python_the_dark_world;

}


int main()
{

	vision_analysis();
	return 0;

}

BOOST_PYTHON_MODULE(opencv)
{

	//definition that out python program will call start and retrieve informatin from our c++ code.
	 def("vision", vision_analysis);

}
