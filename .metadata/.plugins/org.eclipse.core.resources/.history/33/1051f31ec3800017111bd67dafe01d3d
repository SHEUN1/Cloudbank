//============================================================================
// Name        : transistor_vision.cpp
// Author      : 
// Version     :
// Copyright   : Your copyright notice
// Description : Extract objects and their features from a playing game
//============================================================================
#include<stdio.h>
#include<iostream>
#include<opencv2/core/core.hpp>
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include<opencv2/opencv.hpp>
#include<iostream>
#include<vector>
#include <algorithm>
#include <map>
#include <iterator>

#include "yingyang.h"
#include "SeperateObjects.h"
#include "featureextraction.h"


using namespace std;
using namespace cv;

#include <boost/python.hpp>
#include <boost/python/suite/indexing/vector_indexing_suite.hpp>
#include <boost/python/suite/indexing/map_indexing_suite.hpp>

using namespace boost::python;
typedef vector<double> MyList;


boost::python::list vectorToPythonList(vector<double> vectorToSend) {
	typename vector<double>::iterator iter;
	boost::python::list pythonList;
	for (iter = vectorToSend.begin(); iter != vectorToSend.end(); ++iter) {
		pythonList.append(*iter);
	}
	return pythonList;
}

boost::python::dict vectorToPythonList2(vector< vector<KeyPoint> > vectorToSend)
{
	//iterator for each objects
	typename vector< vector<KeyPoint> >::iterator iterEachObject;
	//iterator for each keypoint for each object
	typename vector<KeyPoint>::iterator iterKeyPoints;

	//feature array
	boost::python::list keyPointList;

	//map/dictionary will hold the keypoints acciociated with each object
	boost::python::dict keypointMap;
	int i = 0;


	for (iterEachObject = vectorToSend.begin(); iterEachObject != vectorToSend.end(); ++iterEachObject)
	{

		// hold a collection of all keypoints belonging to the object
		boost::python::list CollectionOfKeypointArray;

		//int j = 0;
		//create a list of individual keypoints
		for(iterKeyPoints = iterEachObject->begin(); iterKeyPoints != iterEachObject->end(); ++iterKeyPoints)
		{
			boost::python::list individualKeypointArray;

			individualKeypointArray.append(iterKeyPoints->pt.x);
			individualKeypointArray.append(iterKeyPoints->pt.y);
			individualKeypointArray.append(iterKeyPoints->size);
			individualKeypointArray.append(iterKeyPoints->angle);
			individualKeypointArray.append(iterKeyPoints->response);
			individualKeypointArray.append(iterKeyPoints->octave);
			keyPointList.append(individualKeypointArray);


		}

		CollectionOfKeypointArray.append(keyPointList);
		keypointMap[i] = CollectionOfKeypointArray;
		++i;

		//typename vector< vector<KeyPoint> >::iterator iterEachObjectMakeSure;
		++iterEachObject;



	}

	//return pythonListInside;
	return keypointMap;
}

boost::python::dict vision_analysis()
{
		//this map will hold all the information on the image such as its position in the frame and feature points
		typedef int object; //object number
		typedef std::pair<int, int > coordinates; //this will hold x,y coordinates of object in the frame
		typedef vector<KeyPoint> featurePoints; // feature points of object


		std::map <object, std::pair<coordinates, featurePoints > > dark_object_info;
		std::map <object, std::pair<coordinates, featurePoints > > light_object_info;
		//hold coordinates to be later inserted for dark contrast objects
		vector<int>dark_x_coordinate;
		vector<int>dark_y_coordinate;
		//hold coordinates to be later inserted for light contrast objects
		vector<int>light_x_coordinate;
		vector<int>light_y_coordinate;

		// turn on script that save get current frame from video game
	    //system("/home/sheun/Gaming_Project/game_vision/gstream_command_to_capture_image &");

	    //read current video_game frame
	    Mat img = imread("/home/sheun/Gaming_Project/game_vision/current_game_frame.jpg");

	    //grayscale, and use imadjust for to get a high contrast version (the basIS for "lightworld")
		Mat gray;
		//convert to grayscale
		cvtColor(img, gray, COLOR_RGB2GRAY);

		//smooth image
		blur(gray, gray, Size(3,3));

		Mat Original_image_clone = gray.clone();

		//convert to binary
		ying_yang world_view;
		Mat dark_world_view = world_view.binary(gray,img);
		Mat light_world_view = world_view.binary_Inverse(gray,img);

		//get objects in each world view and put each of them into a vector
		SeperateObjects worldObjects;
		vector <Mat> dark_world_objects  = worldObjects.BoundBox(dark_world_view, gray,Original_image_clone, 0, dark_x_coordinate, dark_y_coordinate, false); // the 3rd parameter holds the version of the frame image that the boxes will be drawn onto the boxes to be on the original image
		vector <Mat> light_world_objects = worldObjects.BoundBox(light_world_view, gray,Original_image_clone, 1, light_x_coordinate, light_y_coordinate, false);

		feature_extraction features_of_objects;
		vector< vector<KeyPoint> > features_of_dark_world_objects = features_of_objects.featurePoints(dark_world_objects,0, false);
		vector< vector<KeyPoint> > features_of_light_world_objects = features_of_objects.featurePoints(light_world_objects,1, false);

		cout<<dark_world_objects.size()<<endl;
		cout<<features_of_dark_world_objects.at(16).size()<<endl;

		//cvWaitKey();



		//return 0;
		return vectorToPythonList2(features_of_dark_world_objects);
		//return testToPython;//features_of_dark_world_objects;
}

int main()
{

	vision_analysis();
	return 0;

}




BOOST_PYTHON_MODULE(main)
{

	 def("vision", vision_analysis);
	// class_<vision_analysis>("MyClass").def("vision", vision_analysis);
   // class_< vector<double> >("vision").def(vector_indexing_suite<std::vector<double> >());
	//class_< vector<double> >("vision").def(vector_indexing_suite< vector<double> >(vision_analysis) );
	//class_< vector<double> >("vision").def("vision", vision_analysis);

}
